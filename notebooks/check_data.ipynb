{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset directory: c:\\Users\\SIMON\\Desktop\\AMLS2_Cassava_CV\\notebooks\\path\\to\\your\\dataset\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data directory does not exist: path/to/your/dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 167\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing dataset directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(DATASET_DIR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Get all image paths\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m \u001b[43mget_image_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found. Please check the directory path and image extensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 142\u001b[0m, in \u001b[0;36mget_image_paths\u001b[1;34m(data_dir, extensions)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03mGet all image paths from a directory and its subdirectories.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    list: All image paths\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_dir):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData directory does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(data_dir):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData path is not a directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Data directory does not exist: path/to/your/dataset"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def calculate_dataset_statistics(image_paths, sample_size=None, num_workers=8, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculate the global mean and standard deviation of a dataset.\n",
    "    \n",
    "    Args:\n",
    "        image_paths: List of paths to all images in the dataset\n",
    "        sample_size: Number of images to sample (to speed up calculation)\n",
    "                     If None, uses all images\n",
    "        num_workers: Number of parallel workers for processing\n",
    "        verbose: Whether to print detailed logs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mean, std) where each is a numpy array [r, g, b]\n",
    "    \"\"\"\n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No image paths provided\")\n",
    "        \n",
    "    print(f\"Calculating global statistics from {len(image_paths)} images...\")\n",
    "    \n",
    "    # Sample images if needed\n",
    "    if sample_size is not None and sample_size < len(image_paths):\n",
    "        np.random.shuffle(image_paths)\n",
    "        image_paths = image_paths[:sample_size]\n",
    "        print(f\"Sampling {sample_size} images for calculation\")\n",
    "    \n",
    "    # Try to read the first image to verify paths are correct\n",
    "    if verbose:\n",
    "        test_path = image_paths[0]\n",
    "        print(f\"Testing image reading with first image: {test_path}\")\n",
    "        try:\n",
    "            test_img = cv2.imread(test_path)\n",
    "            if test_img is None:\n",
    "                print(f\"WARNING: First image could not be read. Check if path exists: {os.path.exists(test_path)}\")\n",
    "                print(f\"Full absolute path: {os.path.abspath(test_path)}\")\n",
    "            else:\n",
    "                print(f\"Successfully read test image with shape {test_img.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading first image: {e}\")\n",
    "    \n",
    "    # Initialize arrays for means and stds\n",
    "    r_means, g_means, b_means = [], [], []\n",
    "    r_stds, g_stds, b_stds = [], [], []\n",
    "    \n",
    "    error_count = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    # Function to process a single image\n",
    "    def process_image(img_path):\n",
    "        nonlocal error_count\n",
    "        try:\n",
    "            # Read image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                error_count += 1\n",
    "                if verbose and error_count <= 5:  # Limit error messages to avoid flooding console\n",
    "                    print(f\"Warning: Could not read {img_path}\")\n",
    "                    print(f\"  Path exists: {os.path.exists(img_path)}\")\n",
    "                    print(f\"  File size: {os.path.getsize(img_path) if os.path.exists(img_path) else 'N/A'} bytes\")\n",
    "                return None\n",
    "            \n",
    "            # Convert to RGB (OpenCV loads in BGR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Reshape to get all pixels and normalize to [0, 1]\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Calculate mean and std for each channel\n",
    "            means = np.mean(img, axis=(0, 1))\n",
    "            stds = np.std(img, axis=(0, 1))\n",
    "            \n",
    "            return means, stds\n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            if verbose and error_count <= 5:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Process images in parallel\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit tasks\n",
    "        future_to_path = {\n",
    "            executor.submit(process_image, path): path \n",
    "            for path in image_paths\n",
    "        }\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in tqdm(as_completed(future_to_path), total=len(image_paths)):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                processed_count += 1\n",
    "                means, stds = result\n",
    "                r_means.append(means[0])\n",
    "                g_means.append(means[1])\n",
    "                b_means.append(means[2])\n",
    "                r_stds.append(stds[0])\n",
    "                g_stds.append(stds[1])\n",
    "                b_stds.append(stds[2])\n",
    "    \n",
    "    print(f\"Processed {processed_count}/{len(image_paths)} images successfully\")\n",
    "    print(f\"Encountered errors with {error_count} images\")\n",
    "    \n",
    "    # Calculate overall mean and std\n",
    "    if not r_means:\n",
    "        raise ValueError(f\"No valid images found for calculation. All {len(image_paths)} images failed to process.\")\n",
    "    \n",
    "    # Global mean is the mean of all individual image means\n",
    "    global_mean = [\n",
    "        np.mean(r_means),\n",
    "        np.mean(g_means),\n",
    "        np.mean(b_means)\n",
    "    ]\n",
    "    \n",
    "    # For global std, we need a weighted combination of the std values\n",
    "    # This is an approximation using the mean of standard deviations\n",
    "    global_std = [\n",
    "        np.mean(r_stds),\n",
    "        np.mean(g_stds),\n",
    "        np.mean(b_stds)\n",
    "    ]\n",
    "    \n",
    "    return global_mean, global_std\n",
    "\n",
    "def get_image_paths(data_dir, extensions=('.jpg', '.jpeg', '.png')):\n",
    "    \"\"\"\n",
    "    Get all image paths from a directory and its subdirectories.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Root directory containing images\n",
    "        extensions: Tuple of valid file extensions\n",
    "        \n",
    "    Returns:\n",
    "        list: All image paths\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise ValueError(f\"Data directory does not exist: {data_dir}\")\n",
    "        \n",
    "    if not os.path.isdir(data_dir):\n",
    "        raise ValueError(f\"Data path is not a directory: {data_dir}\")\n",
    "        \n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images with extensions {extensions}\")\n",
    "    if len(image_paths) > 0:\n",
    "        print(f\"First few images: {image_paths[:3]}\")\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your dataset directory\n",
    "    DATASET_DIR = r'C:\\Users\\SIMON\\Desktop\\AMLS2_Cassava_CV\\cassava-leaf-disease-classification'\n",
    "    \n",
    "    print(f\"Using dataset directory: {os.path.abspath(DATASET_DIR)}\")\n",
    "    \n",
    "    # Get all image paths\n",
    "    image_paths = get_image_paths(DATASET_DIR)\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"No images found. Please check the directory path and image extensions.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Calculate statistics (using a sample for faster calculation)\n",
    "    # Increase sample_size for more accurate statistics\n",
    "    global_mean, global_std = calculate_dataset_statistics(\n",
    "        image_paths, \n",
    "        sample_size=5000,  # Sample 5000 images (adjust as needed)\n",
    "        num_workers=8,     # Use 8 parallel workers (adjust based on your CPU)\n",
    "        verbose=True       # Enable detailed logging\n",
    "    )\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Global Mean: {global_mean}\")\n",
    "    print(f\"Global Std: {global_std}\")\n",
    "    \n",
    "    # Save to file\n",
    "    np.save('global_mean.npy', global_mean)\n",
    "    np.save('global_std.npy', global_std)\n",
    "    \n",
    "    print(\"Statistics saved to global_mean.npy and global_std.npy\")\n",
    "    \n",
    "    # Example of how to use these values in your model\n",
    "    print(\"\\nIn your model code, set these values:\")\n",
    "    print(f\"GLOBAL_MEAN = {global_mean}\")\n",
    "    print(f\"GLOBAL_STD = {global_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amls2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
